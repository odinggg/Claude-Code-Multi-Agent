# Claude Code 环境变量配置

# ===== LLM 配置 (llama.cpp server) =====
# 模型名称（默认 gemma3:1b，可根据实际部署更改）
LLM_MODEL=gemma3:1b

# llama.cpp server API 地址（默认 http://localhost:8080）
LLM_API_BASE=http://localhost:8080

# 请求超时时间（秒，默认 30）
# LLM_TIMEOUT=30

# ===== 向后兼容配置 =====
# 以下环境变量仍然有效（会自动映射到新配置）
# OLLAMA_MODEL=gemma3:1b
# OLLAMA_API_BASE=http://localhost:8080

# ===== TTS(文本转语音)配置 =====
# TTS 提供商:pyttsx3(本地，无需 API)、openai、elevenlabs
# 默认:pyttsx3(推荐，无需配置)
HOOKS_TTS_PROVIDER=pyttsx3

# 是否启用 TTS 语音播报:true 或 false
# 默认:true
HOOKS_TTS_ENABLED=true